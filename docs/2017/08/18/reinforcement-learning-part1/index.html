<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Corentin Dancette | Reinforcement learning en python sur un jeu simple grâce au Q-learning, Partie 1</title>
<meta name="description" content="Corentin Dancette - personal website and blog
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/2017/08/18/reinforcement-learning-part1/">

<!-- Open Graph -->



<!-- Matomo -->
<p><img src="//cdancette-analytics.l4th.fr/matomo.php?idsite=1&amp;rec=1" style="border:0;" alt="" /></p>
<!-- End Matomo Code -->
  
  
  </head>

  <body class=" sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm sticky-top">
    <div class="container">
      
        
        <a class="navbar-brand title font-weight-lighter" href="https://cdancette.fr/"><span class="font-weight-bold">Corentin</span> Dancette</a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          <ul class="navbar-nav ml-auto flex-nowrap">
            <!-- About -->
            <li class="nav-item ">
              <a class="nav-link" href="/#publications">
                publications
                
              </a>
            </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Reinforcement learning en python sur un jeu simple grâce au Q-learning, Partie 1</h1>
    <p class="post-meta">August 18, 2017</p>
  </header>

  <article class="post-content">
    <p><img src="/assets/qlearning2/capture.gif" alt="Le jeu" /></p>

<p>Un tutoriel pour apprendre le Q-learning sur un jeu simple. Dans cette première partie, on s’interesse au Q-learning stocké dans un tableau de valeurs. Par la suite, on utilisera des reseaux de neurones pour approximer cette table.
<!-- more -->
Tous les codes présentés ici peuvent être trouvés  sur <a href="https://github.com/cdancette/machine-learning-projects/blob/master/q-learning/q-learning-part1.ipynb">github</a>.</p>

<h1 id="quest-ce-que-le-reinforcement-learning-ou-apprentissage-par-renforcement-">Qu’est-ce que le Reinforcement Learning, ou apprentissage par renforcement ?</h1>

<p>C’est un type d’algorithme pour apprendre à un agent à maximiser ses gains dans un environnement ou chaque action lui donne une récompense (positive ou négative).</p>

<h1 id="plan">Plan</h1>

<ul>
  <li><strong>Partie 1</strong> : jeu statique, le terrain ne change pas, utilisation d’un tableau de valeurs (sans réseau de neurones).</li>
  <li><a href="/2017/08/20/reinforcement-learning-part2/">Partie 2</a> : Jeu statique, le terrain ne change pas, utilisation d’un réseau de neurone pour approximer la fonction de valeurs Q.</li>
  <li><a href="/2018/01/03/reinforcement-learning-part3/">Partie 3</a> : Jeu dynamique, le terrain change à chaque partie : utilisation d’un réseau de neurones.</li>
</ul>

<h1 id="description-du-jeu">Description du jeu</h1>

<p>Il s’agit d’un jeu inspiré par l’environnement <a href="https://gym.openai.com/envs/FrozenLake-v0">Frozen Lake</a> de gym, librairie créée par OpenAI, destinée à faciliter le travail de reinforcement learning. Ce jeu est aussi connu sous le nom de Grid World.</p>

<p><img src="/assets/game.png" alt="Jeu" /></p>

<p>On dispose d’un agent situé sur une grille. La grille comporte 3 cases particulières : un mur (en gris), un puit (en rouge), et
une arrivée (en vert). Si l’agent arrive sur le puit ou l’arrivée, le jeu se termine. Le joueur ne peut pas se déplacer sur le mur, et le joueur est récompensé de -1 à chaque fois qu’il arrive sur une case non colorée.</p>

<p>L’environnement peut être doté d’une composante aléatoire : à chaque choix de mouvement (haut, bas, gauche ou droite), l’agent
pourra se déplacer dans une direction non voulue. Ce comportement est paramétrable.</p>

<p>Notre but va donc être de maximiser la somme des récompenses obtenues par l’agent au cours de sa partie.</p>

<p>Le code de l’environnement :</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">random</span>


<span class="k">class</span> <span class="nc">Game</span><span class="p">:</span>
    <span class="n">ACTION_UP</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ACTION_LEFT</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ACTION_DOWN</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">ACTION_RIGHT</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">[</span><span class="n">ACTION_DOWN</span><span class="p">,</span> <span class="n">ACTION_LEFT</span><span class="p">,</span> <span class="n">ACTION_RIGHT</span><span class="p">,</span> <span class="n">ACTION_UP</span><span class="p">]</span>

    <span class="n">ACTION_NAMES</span> <span class="o">=</span> <span class="p">[</span><span class="s">"UP"</span><span class="p">,</span> <span class="s">"LEFT"</span><span class="p">,</span> <span class="s">"DOWN"</span><span class="p">,</span> <span class="s">"RIGHT"</span><span class="p">]</span>

    <span class="n">MOVEMENTS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ACTION_UP</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">ACTION_RIGHT</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ACTION_LEFT</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">ACTION_DOWN</span><span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">num_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ACTIONS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">wrong_action_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alea</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wrong_action_p</span> <span class="o">=</span> <span class="n">wrong_action_p</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">alea</span> <span class="o">=</span> <span class="n">alea</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">generate_game</span><span class="p">()</span>



    <span class="k">def</span> <span class="nf">_position_to_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="s">"""Donne l'identifiant de la position entre 0 et 15"""</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span>

    <span class="k">def</span> <span class="nf">_id_to_position</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">):</span>
        <span class="s">"""Réciproque de la fonction précédente"""</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">id</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="nb">id</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_game</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cases</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">m</span><span class="p">)]</span>
        <span class="n">hole</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cases</span><span class="p">)</span>
        <span class="n">cases</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">hole</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cases</span><span class="p">)</span>
        <span class="n">cases</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cases</span><span class="p">)</span>
        <span class="n">cases</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">cases</span><span class="p">)</span>
        <span class="n">cases</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">start</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">end</span> <span class="o">=</span> <span class="n">end</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">hole</span> <span class="o">=</span> <span class="n">hole</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">block</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">alea</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">alea</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">start</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">generate_game</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_grille</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">grille</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">m</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">grille</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">grille</span>

    <span class="k">def</span> <span class="nf">_get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">alea</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_get_grille</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span>
                    <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">position</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">end</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">hole</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">block</span><span class="p">]]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_position_to_id</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">position</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">move</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="s">"""
        takes an action parameter
        :param action : the id of an action
        :return ((state_id, end, hole, block), reward, is_final, actions)
        """</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">action</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="s">"Invalid action"</span><span class="p">)</span>

        <span class="c1"># random actions sometimes (2 times over 10 default)
</span>        <span class="n">choice</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">choice</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">wrong_action_p</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="p">(</span><span class="n">action</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span>
        <span class="k">elif</span> <span class="n">choice</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">wrong_action_p</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="p">(</span><span class="n">action</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span>

        <span class="n">d_x</span><span class="p">,</span> <span class="n">d_y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">MOVEMENTS</span><span class="p">[</span><span class="n">action</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">position</span>
        <span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">d_x</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">d_y</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">block</span> <span class="o">==</span> <span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">hole</span> <span class="o">==</span> <span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">None</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">end</span> <span class="o">==</span> <span class="p">(</span><span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="mi">10</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span>
        <span class="k">elif</span> <span class="n">new_x</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="ow">or</span> <span class="n">new_y</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">m</span> <span class="ow">or</span> <span class="n">new_x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">new_y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">counter</span> <span class="o">&gt;</span> <span class="mi">190</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_y</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_state</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ACTIONS</span>

    <span class="k">def</span> <span class="nf">print</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">str</span> <span class="o">=</span> <span class="s">""</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">m</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">position</span><span class="p">:</span>
                    <span class="nb">str</span> <span class="o">+=</span> <span class="s">"x"</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">block</span><span class="p">:</span>
                    <span class="nb">str</span> <span class="o">+=</span> <span class="s">"¤"</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">hole</span><span class="p">:</span>
                    <span class="nb">str</span> <span class="o">+=</span> <span class="s">"o"</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="p">.</span><span class="n">end</span><span class="p">:</span>
                    <span class="nb">str</span> <span class="o">+=</span> <span class="s">"@"</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">str</span> <span class="o">+=</span> <span class="s">"."</span>
            <span class="nb">str</span> <span class="o">+=</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure>

<h2 id="partie-1--un-terrain-fixe">Partie 1 : Un terrain fixe.</h2>

<p>Dans ce tutoriel, on va s’intéresser dans un premier temps à un terrain fixe : la position des éléments ne 
sera pas modifiée entre chaque partie. Notre algorithme pourra alors apprendre la structure du terrain par coeur, 
pour pouvoir déplacer l’agent correctement.</p>

<p>Il y a <em>16 états</em> possibles dans l’environnement, on les numerotera donc de 0 à 15, et 4 actions possibles à chaque étape.
Une action “impossible” renverra un état identique à l’état précédent.</p>

<h1 id="q-learning-avec-une-table">Q learning avec une table</h1>

<p>Le Q-learning consiste à déterminer une fonction Q(s, a) qui prend deux paramètres :</p>
<ul>
  <li>s : L’état du système</li>
  <li>a : l’action que l’on veut effectuer</li>
</ul>

<p>Et cette fonction renvoie une valeur, qui est la récompense potentielle que l’on obtiendra à long terme en choisissant cette action.</p>

<p>Ici, nous aurons un faible nombre d’états et d’actions (16 et 4), donc nous pouvons stocker toutes les valeurs dans un tableau.
C’est la méthode la plus précise, lorsque la mémoire le permet. Si le nombre d’état / actions devient trop grand, il sera nécessaire d’approximer la fonction, comme on le verra dans une autre partie.</p>

<h1 id="algorithme-dapprentissage">Algorithme d’apprentissage</h1>

<p>L’algorithme nous permettra de remplir ce tableau de Q-values, pour pouvoir déterminer, à chaque état, l’action optimale
(qui sera en fait la valeur maximale obtenue parmi toutes les actions possibles).</p>

<p>Nous commencons avec un tableau vide, de taille 16 x 4 (16 états, 4 actions).</p>

<p>Puis, nous lançons l’agent, avec des mouvements aléatoires, et à chaque étape, nous pouvons mettre à jour le tableau 
grâce à cette formule</p>

<p><img src="/assets/q-formula.svg" alt="Formule" /> <strong>todo simplifier la formule</strong></p>

<p>C’est cette formule qui constitue le coeur du Q-learning. On va actualiser la valeur de Q(s, a) grâce à la récompense 
effectivement obtenu depuis l’état s en appliquant l’action a, à laquelle on va ajouter la meilleure récompense qu’on pourra obtenir dans le futur.</p>

<p>On implémente ce qu’on vient d’expliquer</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># q learning with table
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">states_n</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">actions_n</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">states_n</span><span class="p">,</span> <span class="n">actions_n</span><span class="p">])</span>

<span class="c1"># Set learning parameters
</span><span class="n">lr</span> <span class="o">=</span> <span class="p">.</span><span class="mi">85</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">.</span><span class="mi">99</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">cumul_reward_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">actions_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">states_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">Game</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># 0.1 chance to go left or right instead of asked direction
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">game</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">]</span>
    <span class="n">cumul_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">d</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="c1"># on choisit une action aléatoire avec une certaine probabilité, qui décroit
</span>        <span class="c1"># TODO : simplifier ça (pas clair)
</span>        <span class="n">Q2</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,:]</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">actions_n</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q2</span><span class="p">)</span>
        <span class="n">s1</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">game</span><span class="p">.</span><span class="n">move</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="n">lr</span><span class="o">*</span><span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">s1</span><span class="p">,:])</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span> <span class="c1"># Fonction de mise à jour de la Q-table
</span>        <span class="n">cumul_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">s1</span>
        <span class="n">actions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">states</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="n">states_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
    <span class="n">actions_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
    <span class="n">cumul_reward_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cumul_reward</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Score over time: "</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">cumul_reward_list</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:])</span><span class="o">/</span><span class="mf">100.0</span><span class="p">))</span>

<span class="n">game</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">game</span><span class="p">.</span><span class="k">print</span><span class="p">()</span></code></pre></figure>

<h1 id="explications-lignes-par-lignes">Explications lignes par lignes</h1>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">states_n</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">actions_n</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">states_n</span><span class="p">,</span> <span class="n">actions_n</span><span class="p">])</span></code></pre></figure>

<p>On définit le nombre d’états (16), et d’actions pour chaque état (4). Et on construit le tableau 
de valeur etat / action Q, rempli de 0.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Set learning parameters
</span><span class="n">lr</span> <span class="o">=</span> <span class="p">.</span><span class="mi">85</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">.</span><span class="mi">99</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">1000</span></code></pre></figure>

<p>On définit les paramètres de l’apprentissage.</p>

<p><code class="language-plaintext highlighter-rouge">lr</code> : learning rate, c’est la vitesse d’apprentissage. Plus il est élevé, plus les nouvelles informations seront 
importantes par rapport aux anciennes.  À 0, l’agent n’apprend rien, et à 1, il ne retiendra pas les anciennes 
infos qu’il a apprises. C’est l’idéal si l’environnement est déterministe (ie 1 etat + 1 action = toujours le même état
et la même récompense). Ici l’environnement n’est pas déterministe, car l’agent peut se tromper de direction. On le place donc à .85 (valeur trouvée par tatonnement).</p>

<p><code class="language-plaintext highlighter-rouge">y</code> : facteur d’actualisation (gamma), entre 0 et 1. : détermine l’importance des récompenses futures. Trop élevé (trop proche de 1), il y a risque de divergence.</p>

<p><code class="language-plaintext highlighter-rouge">num_episodes</code> : le nombre de parties que l’on va faire. 1000 est largement suffisant ici, comme on peut le voir dans les graphiques plus bas.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">game</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">]</span>
    <span class="n">cumul_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">d</span> <span class="o">=</span> <span class="bp">False</span></code></pre></figure>

<p>Initialisation du jeu</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">Q2</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,:]</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">actions_n</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q2</span><span class="p">)</span></code></pre></figure>

<p>Etape importante : ici, on choisit quelle action on va effectuer pour ce tour. 
On a une probabilité <script type="math/tex">{1/(i+1)}</script>de faire une action aléatoire (i = 0 au début, donc l’action est forcément aléatoire). 
Puis cette probabilité décroit au cours du temps.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+</span> <span class="n">lr</span><span class="o">*</span><span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">s1</span><span class="p">,:])</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span> <span class="c1"># Fonction de mise à jour de la Q-table</span></code></pre></figure>

<p>On applique la formule du Q-learning.</p>

<h1 id="performances">Performances</h1>

<p>On peut afficher plusieurs graphiques pour calculer les performances de notre algorithme.
Une courbe pertinente est l’évolution des récompenses cumulées (ie le score total à la fin de la partie).
En effet, le Q-learning est confectionné pour maximiser cette récompense cumulée.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rList</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Cumulative reward'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Étape'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/q-learning-curve-1.png" alt="Graphique de la reward totale" /></p>

<p>On voit ainsi que l’on arrive assez rapidement à un maximum. Le score n’est jamais parfait car il y a de l’aléatoire dans le  jeu (l’agent se trompe de direction 2 fois sur 10), ce qui fait qu’il tombe parfois dans le trou.</p>

<p>Un example, on voit que l’agent évite le trou (représenté par un O).</p>

<p><img src="/assets/game1-run.gif" alt="Jeu" /></p>

<h1 id="la-suite--partie-2--environnement-qui-change-entre-chaque-partie--réseaux-de-neurones">La suite : Partie 2 : environnement qui change entre chaque partie + réseaux de neurones</h1>

<p><a href="/2017/08/20/reinforcement-learning-part2/">Partie 2</a></p>

<p>Si vous avez aimé cet article, n’hésitez pas à m’envoyer un <a href="mailto:contact@cdancette.fr">mail</a>.</p>

<h2 id="resources-en-anglais">Resources (en anglais)</h2>

<ul>
  <li>https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0</li>
  <li>http://outlace.com/rlpart3.html</li>
  <li>https://mpatacchiola.github.io/blog/2016/12/09/dissecting-reinforcement-learning.html</li>
  <li>https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149</li>
</ul>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2021 Corentin Dancette.
    Powered sort_by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







</html>
